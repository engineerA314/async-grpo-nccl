from copy import deepcopy
import json
import logging
from pathlib import Path
import random
import shutil
import time
import uuid
import asyncio
from functools import partial

import ray
from filelock import FileLock, Timeout
from wrapt_timeout_decorator import timeout
from functools import partial
from reward_registry import get_reward_adapter, RewardType

import numpy as np


def cos_fn(t, T, eta_min, eta_max):
    """Basic cosine function component"""
    return eta_min + 0.5 * (eta_max - eta_min) * (1 + np.cos(t * np.pi / T))


def compute_cosine_reward(gen_length, max_length, format_quality, is_correct, 
                          r_c_0=6, r_c_L=5, r_w_0=-10, r_w_L=0, r_f_0=1.0, r_f_L=0.5,
                          exceed_penalty=-10):
    """
    Modification of the cosine reward function from this paper to include format quality.
    'Demystifying Long Chain-of-Thought Reasoning in LLMs' (Yeo et al., 2025)
    arXiv:2502.03373
      
    Parameters:
    gen_length: Generation length
    max_length: Maximum allowed length
    format_quality: 1=correct format, 0=incorrect format (None uses is_correct only)
    is_correct: 1=correct answer, 0=incorrect answer
    r_c_0/r_c_L: Rewards for correct at min/max length
    r_w_0/r_w_L: Rewards for wrong at min/max length
    r_f_0/r_f_L: Rewards for wrong but good format at min/max length
    exceed_penalty: Penalty for exceeding max length
    """
    # Check if generation length exceeds maximum length
    if gen_length >= max_length:
        return exceed_penalty
    
    if is_correct == 1:
        reward = cos_fn(gen_length, max_length, r_c_0, r_c_L)
    else:
        reward = cos_fn(gen_length, max_length, r_w_0, r_w_L)

    reward += cos_fn(gen_length, max_length, r_f_0, r_f_L) if format_quality == 1 else 0
    
    return reward.item()

@ray.remote
class VerifierWorker:
    def __init__(self, worker_id: str):
        self.worker_id = worker_id
        # Configure logging for this worker process
        logging.basicConfig(
            level=logging.INFO,
            format="%(asctime)s - %(name)s (%(process)d) - %(levelname)s - [%(filename)s:%(lineno)d] - %(message)s",
        )
        self.logger = logging.getLogger(__name__)
        # self.logger.debug(f"Initializing VerifierWorker with id: {worker_id}")

    def verify_task(self, sample: dict, reward_fn_name: str, **kwargs) -> dict:
        """Generic verification entry point that applies the named reward adapter."""
        self.logger.debug(f"VerifierWorker {self.worker_id} received task for reward_fn: {reward_fn_name}")
        adapter = get_reward_adapter(reward_fn_name)
        out = adapter(sample, **kwargs)
        if "debug_logs" in out:
            # We are moving away from this, but keep for compatibility
            sample["debug_logs"] = out.pop("debug_logs")
        sample.update(**out)
        sample['reward_success'] = True
        # self.logger.debug(f"VerifierWorker {self.worker_id} finished task. Reward: {sample.get('reward')}")
        return sample

@ray.remote
class VerifierPool:
    def __init__(self, global_num_verifiers: int, write_failed: bool = False, reward_fns: list[RewardType] = None, output_dir: str = None):
        self.node_id = ray.get_runtime_context().get_node_id()
        self.global_num_verifiers = global_num_verifiers
        self.write_failed = write_failed
        self.lock = asyncio.Lock()
        # Create an asyncio.Queue to hold available workers.
        self.verifier_queue = asyncio.Queue()
        # Default to both mathd and sympy if not provided
        self.reward_fns = reward_fns or [RewardType.MATHD, RewardType.SYMPY]
        for _ in range(global_num_verifiers):
            self.create_verifier_worker()
        self.outfile = Path(output_dir) / "failed_samples_verify.jsonl" if output_dir is not None else Path("failed_samples_verify.jsonl")
        self.outfile.unlink(missing_ok=True)
        Path(str(self.outfile) + '.lock').unlink(missing_ok=True)
        
    def create_verifier_worker(self):
        # Create a new worker instance.
        worker = VerifierWorker.options(
            num_cpus=1, 
            scheduling_strategy="SPREAD"
        ).remote(f"verifier_worker_{str(uuid.uuid4())}")
        self.verifier_queue.put_nowait(worker)
        return worker

    async def write_failed_sample(self, sample: dict):
        if self.write_failed:
            try:
                with FileLock(f"{self.outfile}.lock", timeout=20):
                    with open(self.outfile, "a") as f:
                        f.write(json.dumps(sample) + "\n")
            except Timeout:
                pass
        return sample
    
    async def _verify_single(self, sample: dict, mode: str, **kwargs) -> dict:
        # Acquire a worker
        worker = await self.verifier_queue.get()
        try:
            # Dispatch to worker
            result_ref = worker.verify_task.remote(sample, mode, **kwargs)
            result = await asyncio.wait_for(result_ref, 30)
            # Return worker to pool
            self.verifier_queue.put_nowait(worker)
            return result
        except Exception as e:
            # Worker failed: kill and replace
            import traceback
            print(traceback.format_exc())
            ray.kill(worker)
            self.create_verifier_worker()
            # Return a default failure sample
            sample['reward'] = 0.0
            sample['reward_success'] = False
            return sample
    
    async def pick_verified_sample(self, results: list[dict]) -> dict:
        """Pick the best result by prioritizing reward, then success flag."""
        return max(
            results,
            key=lambda r: (
                r.get('reward', 0),
                r.get('reward_success', False),
            ),
        )

    async def verify(self, sample: dict, **kwargs) -> dict:
        """Verify using the configured reward functions list."""
        fn_list = kwargs.get('reward_fns', self.reward_fns)
        tasks = [
            asyncio.create_task(
                self._verify_single(deepcopy(sample), fn, **kwargs)
            ) for fn in fn_list
        ]
        results = await asyncio.gather(*tasks)
        # print(f'\033[38;5;196m\033[1m DEBUG: Results: {results[0]["reward"]}\033[0m', flush=True)
        if not any(r.get('reward_success', False) for r in results):
            await self.write_failed_sample(sample)
        return await self.pick_verified_sample(results)


def get_or_create_verifier_pool(global_num_verifiers: int, write_failed: bool = False, reward_fns: list[RewardType] = None, output_dir: str = None) -> VerifierPool:
    # For simplicity, always create a new instance. In a production setting, you might want to implement a singleton.
    try:
        return VerifierPool.options(name="verifier_pool").remote(global_num_verifiers, write_failed, reward_fns, output_dir)
    except Exception as e:
        return ray.get_actor("verifier_pool")
    
    
